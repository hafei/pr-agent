# PR-Agent Code Review å·¥ä½œæµä¸æ ¸å¿ƒæŠ€æœ¯åˆ†æ

## ä¸€ã€Code Review å®Œæ•´å·¥ä½œæµ

### 1. è§¦å‘é˜¶æ®µ

**Webhook è§¦å‘æµç¨‹ï¼š**

```
ç”¨æˆ·æäº¤ PR â†’ Git Provider (GitHub/GitLab/Bitbucket)
    â†“
è§¦å‘ Webhook â†’ FastAPI æœåŠ¡å™¨
    â†“
æ¥æ”¶ HTTP POST è¯·æ±‚ â†’ éªŒè¯ç­¾å
    â†“
è§£æäº‹ä»¶ç±»å‹ â†’ åˆ¤æ–­æ“ä½œç±»å‹ (opened/reopened/comment)
```

**å…³é”®ä»£ç ï¼š** `pr_agent/servers/github_app.py:38-54`
```python
@router.post("/api/v1/github_webhooks")
async def handle_github_webhooks(
    background_tasks: BackgroundTasks,
    request: Request,
    response: Response
):
    # 1. éªŒè¯ webhook ç­¾å
    # 2. è§£æè¯·æ±‚ä½“
    # 3. æå– installation_id å’Œäº‹ä»¶ç±»å‹
    # 4. æ·»åŠ åå°ä»»åŠ¡å¤„ç†
    background_tasks.add_task(handle_request, body, event=event_header)
```

### 2. PR ä¿¡æ¯æ”¶é›†é˜¶æ®µ

**Git Provider æŠ½è±¡å±‚ï¼š**

```
PRAgent.handle_request()
    â†“
get_git_provider_with_context(pr_url)
    â†“
GitProvider (GitHub/GitLab/Bitbucket/etc.)
    â†“
æ”¶é›† PR ä¿¡æ¯ï¼š
  - PR æ ‡é¢˜å’Œæè¿°
  - æ–‡ä»¶åˆ—è¡¨ (get_files())
  - Diff ä¿¡æ¯ (get_diff_files())
  - è¯­è¨€ç»Ÿè®¡ (get_languages())
  - Commit æ¶ˆæ¯ (get_commit_messages())
  - Issue è¯„è®º (get_issue_comments())
```

**å…³é”®ä»£ç ï¼š** `pr_agent/git_providers/git_provider.py:74-200`

æŠ½è±¡æ¥å£ï¼š
```python
class GitProvider(ABC):
    @abstractmethod
    def get_files(self) -> list: pass

    @abstractmethod
    def get_diff_files(self) -> list[FilePatchInfo]: pass

    @abstractmethod
    def get_pr_description_full(self) -> str: pass

    # ... æ›´å¤šæŠ½è±¡æ–¹æ³•
```

### 3. Diff å¤„ç†ä¸ Token ç®¡ç†é˜¶æ®µ

**Token ç®¡ç†æµç¨‹ï¼š**

```
åˆå§‹åŒ– TokenHandler
    â†“
è®¡ç®— prompt åŸºç¡€ tokens (system + user æ¨¡æ¿)
    â†“
get_pr_diff() - ç”Ÿæˆæ‰©å±• diff
    â†“
æ£€æŸ¥æ˜¯å¦è¶…å‡º token é™åˆ¶
    â†“
å¦‚æœè¶…å‡º â†’ è£å‰ªç­–ç•¥
  - æŒ‰è¯­è¨€ä¼˜å…ˆçº§è£å‰ª
  - æŒ‰æ–‡ä»¶é‡è¦æ€§è£å‰ª
  - æ·»åŠ æœªå¤„ç†æ–‡ä»¶åˆ—è¡¨
    â†“
è¿”å›è£å‰ªåçš„ diff å­—ç¬¦ä¸²
```

**å…³é”®ä»£ç ï¼š** `pr_agent/algo/pr_processing.py:38-142`

```python
def get_pr_diff(
    git_provider: GitProvider,
    token_handler: TokenHandler,
    model: str,
    add_line_numbers_to_hunks: bool = False,
    disable_extra_lines: bool = False
):
    # 1. è·å– diff æ–‡ä»¶
    diff_files = git_provider.get_diff_files()

    # 2. ç”Ÿæˆæ‰©å±• diff (æ·»åŠ ä¸Šä¸‹æ–‡)
    patches_extended, total_tokens, patches_extended_tokens = \
        pr_generate_extended_diff(
            pr_languages,
            token_handler,
            add_line_numbers_to_hunks,
            patch_extra_lines_before=PATCH_EXTRA_LINES_BEFORE,
            patch_extra_lines_after=PATCH_EXTRA_LINES_AFTER
        )

    # 3. æ£€æŸ¥ token é™åˆ¶
    if total_tokens + OUTPUT_BUFFER_TOKENS_SOFT_THRESHOLD < get_max_tokens(model):
        # åœ¨é™åˆ¶å†…ï¼Œè¿”å›å®Œæ•´ diff
        return "\n".join(patches_extended)

    # 4. è¶…å‡ºé™åˆ¶ï¼Œæ‰§è¡Œè£å‰ª
    patches_compressed_list, total_tokens_list, ... = \
        pr_generate_compressed_diff(pr_languages, token_handler, model, ...)

    # 5. æ·»åŠ æœªå¤„ç†æ–‡ä»¶ä¿¡æ¯
    # - æ·»åŠ çš„æ–‡ä»¶åˆ—è¡¨
    # - ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨
    # - åˆ é™¤çš„æ–‡ä»¶åˆ—è¡¨
```

**Diff æ‰©å±•æŠ€æœ¯ï¼š** `pr_agent/algo/git_patch_processing.py:11-31`

```python
def extend_patch(
    original_file_str: str,
    patch_str: str,
    patch_extra_lines_before: int,
    patch_extra_lines_after: int,
    filename: str = "",
    new_file_str: str = ""
) -> str:
    """
    ä¸ºæ¯ä¸ª hunk æ·»åŠ é¢å¤–çš„ä¸Šä¸‹æ–‡è¡Œ
    - patch_extra_lines_before: hunk å‰æ·»åŠ çš„è¡Œæ•°
    - patch_extra_lines_after: hunk åæ·»åŠ çš„è¡Œæ•°
    - æ”¯æŒåŠ¨æ€ä¸Šä¸‹æ–‡ï¼šå¯»æ‰¾æœ€è¿‘çš„å‡½æ•°/ç±»è¾¹ç•Œ
    """
    # 1. è§£æåŸå§‹æ–‡ä»¶å’Œè¡¥ä¸
    # 2. ä¸ºæ¯ä¸ª hunk æ·»åŠ ä¸Šä¸‹æ–‡
    # 3. å¤„ç† old/new code çš„å·®å¼‚
    # 4. è¿”å›æ‰©å±•åçš„ patch
```

### 4. AI Prompt æ„å»ºé˜¶æ®µ

**Jinja2 æ¨¡æ¿æ¸²æŸ“æµç¨‹ï¼š**

```
åŠ è½½ prompt æ¨¡æ¿ (settings/pr_reviewer_prompts.toml)
    â†“
å‡†å¤‡å˜é‡å­—å…¸
  - title, branch, description
  - diff (è£å‰ªåçš„)
  - language, num_pr_files
  - extra_instructions
  - num_max_findings
  - require_score, require_tests, require_security_review
  - commit_messages_str
  - related_tickets (å¦‚æœå­˜åœ¨)
    â†“
Environment.from_string().render(variables)
    â†“
ç”Ÿæˆ system_prompt å’Œ user_prompt
```

**å…³é”®ä»£ç ï¼š** `pr_agent/tools/pr_reviewer.py:213-218`

```python
async def _get_prediction(self, model: str) -> str:
    variables = copy.deepcopy(self.vars)
    variables["diff"] = self.patches_diff  # æ›´æ–° diff

    environment = Environment(undefined=StrictUndefined)

    # æ¸²æŸ“ system prompt
    system_prompt = environment.from_string(
        get_settings().pr_review_prompt.system
    ).render(variables)

    # æ¸²æŸ“ user prompt
    user_prompt = environment.from_string(
        get_settings().pr_review_prompt.user
    ).render(variables)

    # è°ƒç”¨ AI
    response, finish_reason = await self.ai_handler.chat_completion(
        model=model,
        temperature=get_settings().config.temperature,
        system=system_prompt,
        user=user_prompt
    )
    return response
```

**Prompt æ¨¡æ¿ç»“æ„ï¼š** `pr_agent/settings/pr_reviewer_prompts.toml`

```
system prompt:
- å®šä¹‰ AI è§’è‰² (PR-Reviewer)
- è¯´æ˜ä»»åŠ¡ç›®æ ‡ (æä¾›ç®€æ´çš„å»ºè®¾æ€§åé¦ˆ)
- å®šä¹‰ diff æ ¼å¼å±•ç¤ºæ–¹å¼
  - __new hunk__ : æ–°ä»£ç 
  - __old hunk__ : æ—§ä»£ç 
  - è¡Œå·ç”¨äºå¼•ç”¨
- è¯´æ˜ç¬¦å·å«ä¹‰
  - '+' : æ–°å¢ä»£ç 
  - '-' : åˆ é™¤ä»£ç 
  - ' ' : æœªæ”¹å˜ä»£ç 
- ä½¿ç”¨ Pydantic å®šä¹‰ YAML è¾“å‡ºç»“æ„
  - Review Base Model
  - KeyIssuesComponentLink
  - TicketCompliance (å¦‚æœæœ‰å…³è” tickets)
  - ContributionTimeCostEstimate (å¦‚æœå¯ç”¨)
  - TodoSection (å¦‚æœæ‰«æ TODO)
  - å¯é…ç½®å­—æ®µ (require_score, require_tests, require_security_review ç­‰)

user prompt:
--PR Ticket Info-- (å¦‚æœå­˜åœ¨)
- Ticket URL, Title, Labels, Description, Requirements

--PR Info--
- Today's Date, Title, Branch, PR Description
- Questions å’Œ Answers (å¦‚æœæ˜¯ answer æ¨¡å¼)

--PR code diff--
- æ‰©å±•çš„ diff å­—ç¬¦ä¸²

Response:
- YAML æ ¼å¼çš„ç»“æ„åŒ–è¾“å‡º
```

### 5. AI è°ƒç”¨é˜¶æ®µ

**LiteLLM ç»Ÿä¸€æ¥å£æµç¨‹ï¼š**

```
LiteLLMAIHandler.chat_completion()
    â†“
é…ç½® AI æ¨¡å‹å‚æ•°
  - model (gpt-5, claude-3.7-sonnet, etc.)
  - temperature (é»˜è®¤ 0.2)
  - reasoning_effort (ä½/ä¸­/é«˜ï¼Œéƒ¨åˆ†æ¨¡å‹æ”¯æŒ)
  - extended_thinking (Claude æ¨¡å‹æ”¯æŒ)
  - seed (å¦‚æœå¯ç”¨)
  - timeout
    â†“
å‡†å¤‡ messages
  - system role
  - user role
  - (å¯é€‰) image_url (å¦‚æœåˆ†æå›¾ç‰‡)
    â†“
è°ƒç”¨ LiteLLM acompletion()
    â†“
å¤„ç†å“åº”
  - æå– content
  - æå– finish_reason
  - è®°å½•æ—¥å¿—
    â†“
é‡è¯•æœºåˆ¶ (å¤±è´¥æ—¶ä½¿ç”¨ fallback æ¨¡å‹)
```

**å…³é”®ä»£ç ï¼š** `pr_agent/algo/ai_handlers/litellm_ai_handler.py:267-412`

```python
@retry(
    retry=retry_if_exception_type(openai.APIError) &
           retry_if_not_exception_type(openai.RateLimitError),
    stop=stop_after_attempt(MODEL_RETRIES),
)
async def chat_completion(
    self,
    model: str,
    system: str,
    user: str,
    temperature: float = 0.2,
    img_path: str = None
):
    # 1. å‡†å¤‡ messages
    messages = [
        {"role": "system", "content": system},
        {"role": "user", "content": user}
    ]

    # 2. å¤„ç†ç‰¹æ®Šæ¨¡å‹å‚æ•°
    kwargs = {
        "model": model,
        "messages": messages,
        "timeout": get_settings().config.ai_timeout,
    }

    # æ·»åŠ  temperature (å¦‚æœæ¨¡å‹æ”¯æŒ)
    if model not in self.no_support_temperature_models:
        kwargs["temperature"] = temperature

    # æ·»åŠ  reasoning_effort (å¦‚æœæ¨¡å‹æ”¯æŒ)
    if model in self.support_reasoning_models:
        kwargs["reasoning_effort"] = get_settings().config.reasoning_effort

    # Claude extended thinking
    if model in self.claude_extended_thinking_models:
        kwargs = self._configure_claude_extended_thinking(model, kwargs)

    # 3. è°ƒç”¨ LiteLLM
    response = await acompletion(**kwargs)

    # 4. æå–ç»“æœ
    resp = response["choices"][0]['message']['content']
    finish_reason = response["choices"][0]['finish_reason']

    return resp, finish_reason
```

**æ”¯æŒçš„ AI æ¨¡å‹ï¼š**
- OpenAI: GPT-5, GPT-4o, GPT-4 Turbo
- Anthropic: Claude 3.7 Sonnet (æ”¯æŒ extended thinking)
- Google: Gemini
- AWS Bedrock
- Azure OpenAI
- HuggingFace
- Ollama
- DeepSeek, Mistral, Groq, Replicate, xAI

### 6. å“åº”è§£æä¸æ ¼å¼åŒ–é˜¶æ®µ

**YAML è§£ææµç¨‹ï¼š**

```
AI è¿”å› YAML å­—ç¬¦ä¸²
    â†“
load_yaml() (è‡ªå®šä¹‰è§£æå™¨)
    â†“
å¤„ç† Pydantic æ¨¡å‹å®šä¹‰
  - Review (ä¸»ç»“æ„)
  - KeyIssuesComponentLink (å…³é”®é—®é¢˜)
  - TicketCompliance (ticket åˆè§„æ£€æŸ¥)
  - ContributionTimeCostEstimate (æ—¶é—´æˆæœ¬ä¼°ç®—)
  - TodoSection (TODO æ‰«æ)
    â†“
convert_to_markdown_v2()
    â†“
ç”Ÿæˆ Markdown æ ¼å¼çš„ review
  - æ·»åŠ æ ‡é¢˜å’Œå¾½ç« 
  - æ ¼å¼åŒ– key_issues (å¯ç‚¹å‡»é“¾æ¥)
  - æ·»åŠ å®‰å…¨å®¡æŸ¥éƒ¨åˆ†
  - æ·»åŠ æµ‹è¯•æ£€æŸ¥
  - æ·»åŠ è¯„åˆ† (å¦‚æœå¯ç”¨)
  - æ·»åŠ åŠªåŠ›ä¼°ç®— (å¦‚æœå¯ç”¨)
  - æ·»åŠ  labels (å¦‚æœå¯ç”¨)
```

**å…³é”®ä»£ç ï¼š** `pr_agent/tools/pr_reviewer.py:229-279`

```python
def _prepare_pr_review(self) -> str:
    """
    å‡†å¤‡ PR reviewï¼Œå¤„ç† AI é¢„æµ‹å¹¶ç”Ÿæˆ markdown æ ¼å¼çš„åé¦ˆ
    """
    # 1. è§£æ YAML
    data = load_yaml(
        self.prediction.strip(),
        keys_fix_yaml=[...],  # ä¿®å¤å¸¸è§æ ¼å¼é—®é¢˜
        first_key='review',
        last_key='security_concerns'
    )

    # 2. æ£€æŸ¥å¿…éœ€å­—æ®µ
    if 'review' not in data:
        get_logger().exception("Failed to parse review data")
        return ""

    # 3. è½¬æ¢ä¸º Markdown
    markdown_text = convert_to_markdown_v2(
        data,
        self.git_provider.is_supported("gfm_markdown"),  # GitHub Flavored Markdown
        incremental_review_markdown_text,  # å¢é‡ review ä¿¡æ¯
        git_provider=self.git_provider,
        files=self.git_provider.get_diff_files()
    )

    # 4. æ·»åŠ å¸®åŠ©æ–‡æœ¬ (å¦‚æœå¯ç”¨)
    if get_settings().pr_reviewer.enable_help_text:
        markdown_text += HelpMessage.get_review_usage_guide()

    # 5. è¾“å‡ºç›¸å…³é…ç½® (å¦‚æœå¯ç”¨)
    if get_settings().config.output_relevant_configurations:
        markdown_text += show_relevant_configurations('pr_reviewer')

    # 6. è®¾ç½® labels (å¦‚æœå¯ç”¨)
    self.set_review_labels(data)

    return markdown_text
```

### 7. ç»“æœå‘å¸ƒé˜¶æ®µ

**å‘å¸ƒæµç¨‹ï¼š**

```
å‡†å¤‡å‘å¸ƒ
    â†“
æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘å¸ƒ
  - publish_output=true
  - publish_output_no_suggestions=true æˆ–æœ‰å®é™…å»ºè®®
    â†“
publish_persistent_comment() æˆ– publish_comment()
    â†“
Git Provider å‘å¸ƒåˆ° PR
  - GitHub: PR è¯„è®º + Labels
  - GitLab: MR è¯„è®º + Labels
  - Bitbucket: PR è¯„è®º
    â†“
ç§»é™¤ä¸´æ—¶ "Preparing review..." è¯„è®º
    â†“
æ›´æ–°æŒä¹…è¯„è®º (å¦‚æœå¯ç”¨)
  - æ·»åŠ  header: "## PR Reviewer Guide ğŸ”"
  - æ”¯æŒå¤šæ¬¡æ›´æ–°åŒä¸€ä¸ªè¯„è®º
```

**å…³é”®ä»£ç ï¼š** `pr_agent/tools/pr_reviewer.py:172-182`

```python
# å‘å¸ƒ review
if get_settings().pr_reviewer.persistent_comment and \
   not self.incremental.is_incremental:
    final_update_message = get_settings().pr_reviewer.final_update_message
    self.git_provider.publish_persistent_comment(
        pr_review,
        initial_header=f"{PRReviewHeader.REGULAR.value} ğŸ”",
        update_header=True,
        final_update_message=final_update_message
    )
else:
    self.git_provider.publish_comment(pr_review)

self.git_provider.remove_initial_comment()
```

### 8. Label è®¾ç½®é˜¶æ®µ

**Label é€»è¾‘ï¼š**

```
è§£æ review æ•°æ®
    â†“
æå–æ ‡ç­¾ä¿¡æ¯
  - Review effort [1-5]/5 (å¦‚æœå¯ç”¨)
  - Possible security concern (å¦‚æœå¯ç”¨ä¸”å‘ç°å®‰å…¨é—®é¢˜)
    â†“
æ›´æ–° PR labels
  - è·å–å½“å‰ labels
  - è¿‡æ»¤æ‰æ—§çš„ review labels
  - æ·»åŠ æ–°çš„ review labels
  - å‘å¸ƒæ›´æ–°åçš„ labels
```

**å…³é”®ä»£ç ï¼š** `pr_agent/tools/pr_reviewer.py:365-415`

```python
def set_review_labels(self, data):
    if not get_settings().config.publish_output:
        return

    # 1. æ£€æŸ¥æ˜¯å¦ç”Ÿæˆç›¸å…³è¾“å‡º
    if not get_settings().pr_reviewer.require_estimate_effort_to_review:
        get_settings().pr_reviewer.enable_review_labels_effort = False

    if not get_settings().pr_reviewer.require_security_review:
        get_settings().pr_reviewer.enable_review_labels_security = False

    # 2. å‡†å¤‡ labels
    review_labels = []

    # Review effort label
    if get_settings().pr_reviewer.enable_review_labels_effort:
        estimated_effort = data['review']['estimated_effort_to_review_[1-5]']
        estimated_effort_number = int(str(estimated_effort).split(',')[0])
        if 1 <= estimated_effort_number <= 5:
            review_labels.append(f'Review effort {estimated_effort_number}/5')

    # Security concern label
    if get_settings().pr_reviewer.enable_review_labels_security:
        security_concerns = data['review']['security_concerns']
        if 'yes' in security_concerns.lower():
            review_labels.append('Possible security concern')

    # 3. æ›´æ–° PR labels
    current_labels = self.git_provider.get_pr_labels(update=True)
    current_labels_filtered = [
        label for label in current_labels
        if not label.lower().startswith('review effort') and
           not label.lower().startswith('possible security concern')
    ]
    new_labels = review_labels + current_labels_filtered

    if sorted(new_labels) != sorted(current_labels):
        self.git_provider.publish_labels(new_labels)
```

---

## äºŒã€æ ¸å¿ƒæŠ€æœ¯æ¶æ„

### 1. åˆ†å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Webhook/CLI å…¥å£å±‚                  â”‚
â”‚  (FastAPI Server, CLI, GitHub Actions)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PRAgent æ ¸å¿ƒåè°ƒå±‚              â”‚
â”‚  - å‘½ä»¤è·¯ç”± (review/describe/improve/etc.)    â”‚
â”‚  - å‚æ•°è§£æå’ŒéªŒè¯                               â”‚
â”‚  - é…ç½®ç®¡ç† (Dynaconf)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Tool å±‚ (å·¥å…·ç±»)                â”‚
â”‚  - PRReviewer (/review)                         â”‚
â”‚  - PRDescription (/describe)                     â”‚
â”‚  - PRCodeSuggestions (/improve)                 â”‚
â”‚  - PRQuestions (/ask)                           â”‚
â”‚  - PRAddDocs (/add_docs)                        â”‚
â”‚  - PRUpdateChangelog (/update_changelog)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Algo å±‚      â”‚  â”‚  â”‚ AI Handler å±‚  â”‚
â”‚ - Diff å¤„ç†  â”‚  â”‚  â”‚ - LiteLLM       â”‚
â”‚ - Token ç®¡ç†  â”‚  â”‚  â”‚ - OpenAI        â”‚
â”‚ - æ–‡ä»¶è¿‡æ»¤   â”‚  â”‚  â”‚ - LangChain     â”‚
â”‚ - Prompt æ¸²æŸ“â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚
â”‚ Git Provider  â”‚  â”‚
â”‚ å±‚           â”‚  â”‚
â”‚ - GitHub      â”‚  â”‚
â”‚ - GitLab      â”‚  â”‚
â”‚ - Bitbucket   â”‚  â”‚
â”‚ - Gitea       â”‚  â”‚
â”‚ - Azure DevOpsâ”‚  â”‚
â”‚ - Gerrit      â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Configuration   â”‚
        â”‚  å±‚              â”‚
        â”‚  - TOML files    â”‚
        â”‚  - Env vars      â”‚
        â”‚  - CLI args      â”‚
        â”‚  - Secret stores  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. å¼‚æ­¥ç¼–ç¨‹æ¨¡å‹

**å…¨é¢é‡‡ç”¨ async/awaitï¼š**

```python
# Webhook å¤„ç†
@router.post("/api/v1/github_webhooks")
async def handle_github_webhooks(
    background_tasks: BackgroundTasks,
    request: Request
):
    # ä½¿ç”¨ await å¤„ç†å¼‚æ­¥ I/O
    body = await request.json()

    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(handle_request, body, ...)

# Tool æ‰§è¡Œ
async def run(self) -> None:
    # AI è°ƒç”¨æ˜¯å¼‚æ­¥çš„
    await retry_with_fallback_models(self._prepare_prediction)

# AI Handler
async def chat_completion(self, model: str, ...):
    # LiteLLM å¼‚æ­¥è°ƒç”¨
    response = await acompletion(**kwargs)
```

**ä¼˜åŠ¿ï¼š**
- é«˜å¹¶å‘å¤„ç†å¤šä¸ª webhook
- éé˜»å¡ AI API è°ƒç”¨
- é«˜æ•ˆå¤„ç† Git Provider API è¯·æ±‚
- åå°ä»»åŠ¡ä¸é˜»å¡å“åº”

### 3. é…ç½®ç®¡ç†ç³»ç»Ÿ

**Dynaconf å¤šå±‚é…ç½®ï¼š**

```
ä¼˜å…ˆçº§ (ä»é«˜åˆ°ä½):
1. CLI å‚æ•° (--key=value)
   - å®‰å…¨é™åˆ¶ï¼šç¦æ­¢ä¼ é€’æ•æ„Ÿé…ç½®
   - å®æ—¶æ›´æ–°è®¾ç½®

2. ç¯å¢ƒå˜é‡ (OPENAI__KEY, ANTHROPIC__KEY)
   - å®¹å™¨åŒ–éƒ¨ç½²å‹å¥½
   - æœºå¯†ä¿¡æ¯å®‰å…¨å­˜å‚¨

3. ä»“åº“é…ç½® (.pr_agent.toml)
   - ä»“åº“ç‰¹å®šè®¾ç½®
   - åŠ¨æ€åŠ è½½ï¼ˆæ‰«æ .git rootï¼‰

4. Wiki è®¾ç½®æ–‡ä»¶
   - ä» repo wiki åŠ è½½é…ç½®
   - å›¢é˜Ÿå…±äº«é…ç½®

5. å…¨å±€è®¾ç½® (pr_agent/settings/)
   - configuration.toml (ä¸»é…ç½®)
   - ignore.toml (å¿½ç•¥æ¨¡å¼)
   - language_extensions.toml (è¯­è¨€æ‰©å±•)
   - pr_reviewer_prompts.toml (review prompts)
   - ... (å…¶ä»– prompt æ–‡ä»¶)

6. é»˜è®¤å€¼ (ä»£ç ä¸­)
```

**è‡ªå®šä¹‰åˆå¹¶åŠ è½½å™¨ï¼š** `pr_agent/custom_merge_loader.py`

```python
# åˆå¹¶ TOML æ–‡ä»¶çš„ç‰¹æ®Šé€»è¾‘
# - åˆå¹¶ sections
# - é‡å†™ overlapping values
# - è€Œä¸æ˜¯å®Œå…¨æ›¿æ¢ section
```

**é…ç½®è®¿é—®ï¼š** `pr_agent/config_loader.py`

```python
from dynaconf import Dynaconf

# å…¨å±€è®¾ç½®
global_settings = Dynaconf(
    core_loaders=[],
    loaders=['pr_agent.custom_merge_loader', ...],
    merge_enabled=True,
    settings_files=[...],
    **dynconf_kwargs
)

# å¸¦ä¸Šä¸‹æ–‡çš„è®¾ç½®ï¼ˆæ¯ä¸ª PR è¯·æ±‚ï¼‰
def get_settings(use_context=False):
    try:
        return context["settings"]  # ä» starlette_context
    except Exception:
        return global_settings  # å›é€€åˆ°å…¨å±€
```

### 4. Token ç®¡ç†ç­–ç•¥

**æ™ºèƒ½ Token è®¡æ•°ï¼š** `pr_agent/algo/token_handler.py`

```python
class TokenHandler:
    def __init__(self, pr, vars, system, user):
        # 1. è·å–ç¼–ç å™¨ï¼ˆæ¨¡å‹ç‰¹å®šï¼‰
        self.encoder = TokenEncoder.get_token_encoder()

        # 2. è®¡ç®— prompt åŸºç¡€ tokens
        self.prompt_tokens = self._get_system_user_tokens(
            pr, self.encoder, vars, system, user
        )

    def count_tokens(self, patch: str, force_accurate: bool = False):
        # ä¼°ç®— token æ•°
        encoder_estimate = len(self.encoder.encode(patch))

        if not force_accurate:
            return encoder_estimate

        # å‡†ç¡®è®¡ç®—ï¼ˆä½¿ç”¨æ¨¡å‹ç‰¹å®š APIï¼‰
        return self._get_token_count_by_model_type(patch, encoder_estimate)
```

**ç¼–ç å™¨é€‰æ‹©ç­–ç•¥ï¼š**

```python
class TokenEncoder:
    @classmethod
    def get_token_encoder(cls):
        model = get_settings().config.model

        # OpenAI æ¨¡å‹ï¼šä½¿ç”¨ tiktoken encoding_for_model
        if "gpt" in cls._model:
            cls._encoder_instance = encoding_for_model(cls._model)
        else:
            # å…¶ä»–æ¨¡å‹ï¼šä½¿ç”¨ o200k_base (é€šç”¨)
            cls._encoder_instance = get_encoding("o200k_base")

        return cls._encoder_instance
```

**Token é™åˆ¶é…ç½®ï¼š**

```python
# pr_agent/algo/__init__.py
MAX_TOKENS = {
    "gpt-5-2025-08-07": 1000000,
    "o4-mini": 200000,
    "claude-3-7-sonnet-20250219": 200000,
    "gemini-2.5-pro": 1000000,
    # ... æ›´å¤šæ¨¡å‹
}

# pr_agent/settings/configuration.toml
[config]
max_description_tokens = 500
max_commits_tokens = 500
max_model_tokens = 32000  # ç¡¬æ€§é™åˆ¶
model_token_count_estimate_factor = 0.3  # å¢åŠ å®‰å…¨ä½™é‡
```

### 5. Diff å¤„ç†æŠ€æœ¯

**ç»Ÿä¸€ diff æ ¼å¼ï¼š**

```
## File: 'src/example.py'

__new hunk__
11  unchanged code line0
12  unchanged code line1
13 +new code line2 added
14  unchanged code line3
__old hunk__
 unchanged code line0
 unchanged code line1
-old code line2 removed
 unchanged code line3
```

**å…³é”®æŠ€æœ¯ï¼š** `pr_agent/algo/git_patch_processing.py`

1. **Patch æ‰©å±•ï¼š**
   - åœ¨ hunk å‰åæ·»åŠ ä¸Šä¸‹æ–‡è¡Œ
   - `patch_extra_lines_before`: hunk å‰è¡Œæ•°
   - `patch_extra_lines_after`: hunk åè¡Œæ•°

2. **åŠ¨æ€ä¸Šä¸‹æ–‡ï¼š**
   - `allow_dynamic_context=true`ï¼šæ™ºèƒ½å¯»æ‰¾å‡½æ•°/ç±»è¾¹ç•Œ
   - `max_extra_lines_before_dynamic_context`: æœ€å¤š 10 è¡Œ
   - å‘å‰å¯»æ‰¾æœ€è¿‘çš„ section headerï¼ˆclass/functionï¼‰

3. **è¡Œå·æ·»åŠ ï¼š**
   - `add_line_numbers_to_hunks=true`
   - ä¸º new hunk æ·»åŠ è¡Œå·
   - ä¾¿äº AI å¼•ç”¨ç‰¹å®šè¡Œ

4. **Hunk è§£è€¦ï¼š**
   - `decouple_and_convert_to_hunks_with_line_numbers`
   - åˆ†ç¦» __new_hunk__ å’Œ __old_hunk__
   - æ·»åŠ è¡Œå·æ ‡è¯†

**æ‰©å±•ç®—æ³•ï¼š** `pr_agent/algo/git_patch_processing.py:56-200`

```python
def process_patch_lines(
    patch_str,
    original_file_str,
    patch_extra_lines_before,
    patch_extra_lines_after,
    new_file_str=""
):
    # 1. è§£ææ–‡ä»¶
    file_original_lines = original_file_str.splitlines()
    file_new_lines = new_file_str.splitlines()
    patch_lines = patch_str.splitlines()

    # 2. è§£æ hunk headers
    # @@ -old_start,old_size +new_start,new_size @@
    RE_HUNK_HEADER = re.compile(
        r"^@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@[ ]?(.*)"
    )

    # 3. å¤„ç†æ¯ä¸ª hunk
    for i, line in enumerate(patch_lines):
        if line.startswith('@@'):
            # æå– hunk ä¿¡æ¯
            start1, size1, start2, size2 = extract_hunk_headers(match)

            # 4. æ‰©å±•ä¸Šä¸‹æ–‡
            if patch_extra_lines_before > 0:
                # æ·»åŠ  hunk å‰çš„è¡Œ
                delta_lines_before = file_original_lines[
                    extended_start1 - 1 : start1 - 1
                ]

            if patch_extra_lines_after > 0:
                # æ·»åŠ  hunk åçš„è¡Œ
                delta_lines_after = file_original_lines[
                    start1 + size1 - 1 : start1 + size1 - 1 + patch_extra_lines_after
                ]

            # 5. åŠ¨æ€ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if allow_dynamic_context:
                # å¯»æ‰¾æœ€è¿‘çš„ section header
                # è°ƒæ•´ä¸Šä¸‹æ–‡èŒƒå›´åˆ°å‡½æ•°/ç±»è¾¹ç•Œ
```

### 6. AI æ¨¡å‹ç»Ÿä¸€æ¥å£

**BaseAiHandler æŠ½è±¡ï¼š** `pr_agent/algo/ai_handlers/base_ai_handler.py`

```python
class BaseAiHandler(ABC):
    @abstractmethod
    def __init__(self):
        pass

    @property
    @abstractmethod
    def deployment_id(self):
        pass

    @abstractmethod
    async def chat_completion(
        self,
        model: str,
        system: str,
        user: str,
        temperature: float = 0.2,
        img_path: str = None
    ):
        """
        AI æ¨¡å‹è°ƒç”¨æ¥å£
        """
        pass
```

**LiteLLM å®ç°ï¼š** `pr_agent/algo/ai_handlers/litellm_ai_handler.py`

**æ”¯æŒçš„åŠŸèƒ½ï¼š**

1. **å¤šæ¨¡å‹æä¾›å•†ï¼š**
   - OpenAI: `OPENAI.KEY`
   - Anthropic: `ANTHROPIC.KEY`
   - Google: `GOOGLE_AI_STUDIO.GEMINI_API_KEY`
   - AWS: `AWS.AWS_ACCESS_KEY_ID`, `AWS.AWS_SECRET_ACCESS_KEY`
   - Azure: `OPENAI.API_TYPE=azure`, `OPENAI.API_VERSION`
   - HuggingFace: `HUGGINGFACE.KEY`
   - Ollama: `OLLAMA.API_BASE`
   - æ›´å¤š...

2. **é«˜çº§æ¨¡å‹å‚æ•°ï¼š**
   - `reasoning_effort`: æ¨ç†å¼ºåº¦
   - `extended_thinking`: Claude æ‰©å±•æ€è€ƒ
   - `temperature`: æ¸©åº¦æ§åˆ¶
   - `seed`: éšæœºç§å­
   - `timeout`: API è¶…æ—¶
   - `max_tokens`: æœ€å¤§è¾“å‡º tokens

3. **é‡è¯•æœºåˆ¶ï¼š**
   ```python
   @retry(
       retry=retry_if_exception_type(openai.APIError) &
              retry_if_not_exception_type(openai.RateLimitError),
       stop=stop_after_attempt(MODEL_RETRIES),  # 2 æ¬¡
   )
   ```

4. **Fallback æ¨¡å‹ï¼š**
   - ä¸»æ¨¡å‹å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢
   - `fallback_models=["o4-mini"]`

5. **æµå¼å“åº”ï¼š**
   - æŸäº›æ¨¡å‹éœ€è¦æµå¼è°ƒç”¨
   - `STREAMING_REQUIRED_MODELS`
   - è‡ªåŠ¨æ£€æµ‹å’Œå¤„ç†

**æ¨¡å‹ç‰¹å®šé…ç½®ï¼š**

```python
# GPT-5 (reasoning models)
if model.startswith('gpt-5'):
    if model.endswith('_thinking'):
        kwargs["reasoning_effort"] = 'low'
    else:
        kwargs["reasoning_effort"] = 'minimal'
    kwargs["allowed_openai_params"] = ["reasoning_effort"]

# Claude extended thinking
if model in self.claude_extended_thinking_models:
    kwargs["thinking"] = {
        "type": "enabled",
        "budget_tokens": extended_thinking_budget_tokens
    }
    kwargs["max_tokens"] = extended_thinking_max_output_tokens
    kwargs["temperature"] = 1  # å¿…é¡»ä¸º 1
```

### 7. æ¨¡æ¿å¼•æ“ (Jinja2)

**Prompt æ¨¡æ¿åŒ–ï¼š**

```python
from jinja2 import Environment, StrictUndefined

environment = Environment(undefined=StrictUndefined)

# æ¸²æŸ“æ¨¡æ¿
system_prompt = environment.from_string(template_str).render(variables)
```

**æ¡ä»¶æ¸²æŸ“ï¼š**

```jinja2
{%- if require_score %}
  score: str = Field(description="Rate this PR on a scale of 0-100")
{%- endif %}

{%- if related_tickets %}
  ticket_compliance_check: List[TicketCompliance]
{%- endif %}

{%- for ticket in related_tickets %}
Ticket: {{ ticket.title }}
{%- endfor %}
```

**æ¨¡æ¿ç‰¹ç‚¹ï¼š**
- ä½¿ç”¨ `StrictUndefined`ï¼šæœªå®šä¹‰å˜é‡æŠ›å‡ºé”™è¯¯
- æ”¯æŒæ¡ä»¶åˆ¤æ–­ (`if`)
- æ”¯æŒå¾ªç¯ (`for`)
- è¿‡æ»¤ (`|trim`, `|upper` ç­‰)
- å­—ç¬¦ä¸²æ‹¼æ¥
- YAML è¾“å‡ºç»“æ„

### 8. æ–‡ä»¶è¿‡æ»¤ä¸å¿½ç•¥

**æ–‡ä»¶è¿‡æ»¤æµç¨‹ï¼š** `pr_agent/algo/file_filter.py`

```python
def filter_ignored(files):
    # 1. è·å–å¿½ç•¥è§„åˆ™
    glob_patterns = global_settings.ignore.glob
    regex_patterns = global_settings.ignore.regex

    # 2. è¿‡æ»¤æ–‡ä»¶
    filtered_files = []
    for file in files:
        filename = file.filename

        # Glob æ¨¡å¼åŒ¹é…
        if any(fnmatch(filename, pattern) for pattern in glob_patterns):
            continue

        # Regex æ¨¡å¼åŒ¹é…
        if any(re.match(pattern, filename) for pattern in regex_patterns):
            continue

        # è¯­è¨€æ¡†æ¶å¿½ç•¥
        language = file.language
        if language in global_settings.ignore.language_framework:
            continue

        filtered_files.append(file)

    return filtered_files
```

**å¿½ç•¥é…ç½®ï¼š** `pr_agent/settings/ignore.toml`

```toml
[ignore]
# Glob æ¨¡å¼
glob = [
    "*.md",
    "*.txt",
    "*.json",
    "generated/*"
]

# Regex æ¨¡å¼
regex = [
    "^generated/",
    ".*\\.(pb|grpc)$"
]

# è¯­è¨€æ¡†æ¶ï¼ˆè‡ªåŠ¨ç”Ÿæˆçš„ä»£ç ï¼‰
language_framework = [
    "protobuf",
    "go_gen"
]
```

### 9. å®‰å…¨æœºåˆ¶

**1. ç­¾åéªŒè¯ï¼š** `pr_agent/servers/utils.py`

```python
def verify_signature(body_bytes, secret, signature_header):
    """
    éªŒè¯ GitHub webhook ç­¾å
    """
    import hmac
    import hashlib

    if not secret:
        return

    # è®¡ç®— HMAC-SHA256
    hmac_obj = hmac.new(
        secret.encode('utf-8'),
        body_bytes,
        hashlib.sha256
    )
    digest = "sha256=" + hmac_obj.hexdigest()

    # æ¯”è¾ƒç­¾å
    if not hmac.compare_digest(digest, signature_header):
        raise ValueError("Invalid signature")
```

**2. ç¦æ­¢çš„ CLI å‚æ•°ï¼š** `pr_agent/algo/cli_args.py`

```python
class CliArgs:
    @staticmethod
    def validate_user_args(args: list) -> (bool, str):
        # è§£ç ç¦æ­¢çš„å‚æ•°ï¼ˆBase64 ç¼–ç ï¼‰
        _encoded_args = 'c2hhcmVkX3NlY3JldDpkdXNlc3RfaW5hYmxlX2FhcHByb3ZhbDpZW5hYmxlX2Z0cnV0aW9uOmludmlzaWJsZV9hdXRvX2FwcHJvdmFsOmVuYWJsZV9tYW51YWxfYXBwcm92YWw6ZW5hYmxlX2F1dG9fYXBwcm92YWw='

        forbidden_cli_args = []
        for e in _encoded_args.split(':'):
            forbidden_cli_args.append(b64decode(e).decode())

        # éªŒè¯å‚æ•°
        for arg in args:
            if arg.startswith('--'):
                arg_word = arg.lower()
                for forbidden_arg in forbidden_cli_args:
                    if forbidden_arg in arg_word:
                        return False, forbidden_arg

        return True, ""
```

**ç¦æ­¢çš„å‚æ•°åŒ…æ‹¬ï¼š**
- `openai.key`, `anthropic.key` (API å¯†é’¥)
- `git_provider`, `app_name` (ç³»ç»Ÿé…ç½®)
- `enable_auto_approval`, `approve_pr_on_self_review` (å…³é”®é…ç½®)
- `secret_provider`, `base_url` (å®‰å…¨è®¾ç½®)

**3. æœºå¯†ç®¡ç†ï¼š** `pr_agent/secret_providers/`

```python
# AWS Secrets Manager
class AWSSecretsManagerProvider:
    def get_secret(self, secret_name: str):
        client = boto3.client('secretsmanager')
        response = client.get_secret_value(SecretId=secret_name)
        return response['SecretString']

# Google Cloud Storage
class GoogleCloudStorageSecretProvider:
    def get_secret(self, bucket_name: str, object_name: str):
        client = storage.Client()
        bucket = client.bucket(bucket_name)
        blob = bucket.blob(object_name)
        return blob.download_as_text()
```

**4. èº«ä»½éªŒè¯ï¼š** `pr_agent/identity_providers/`

```python
class IdentityProvider(ABC):
    @abstractmethod
    def verify_eligibility(
        self,
        provider: str,
        user_id: str,
        pr_url: str
    ) -> Eligibility:
        """
        éªŒè¯ç”¨æˆ·æ˜¯å¦æœ‰èµ„æ ¼ä½¿ç”¨ PR-Agent
        """
        pass
```

---

## ä¸‰ã€æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. Token ä¼˜åŒ–

**åŠ¨æ€è£å‰ªï¼š**
- æŒ‰è¯­è¨€ä¼˜å…ˆçº§ï¼šä¸»è¦è¯­è¨€ä¼˜å…ˆ
- æŒ‰æ–‡ä»¶é‡è¦æ€§ï¼šä¿®æ”¹ > æ–°å¢
- å¤šæ‰¹æ¬¡ï¼šå¤§ PR åˆ†å¤šä¸ª patch å¤„ç†

**é…ç½®ï¼š**
```toml
[config]
patch_extra_lines_before = 5
patch_extra_lines_after = 1
max_extra_lines_before_dynamic_context = 10
large_patch_policy = "clip"  # æˆ– "skip"
```

### 2. å¹¶å‘å¤„ç†

**åå°ä»»åŠ¡ï¼š**
```python
# FastAPI BackgroundTasks
background_tasks.add_task(handle_request, body, event=event)
```

**å¼‚æ­¥ I/Oï¼š**
- æ‰€æœ‰ AI è°ƒç”¨å¼‚æ­¥
- æ‰€æœ‰ Git Provider API è°ƒç”¨å¼‚æ­¥
- ä¸é˜»å¡ webhook å“åº”

### 3. ç¼“å­˜ç­–ç•¥

**é…ç½®ç¼“å­˜ï¼š**
```python
from starlette_context import context

# æ¯ä¸ª PR è¯·æ±‚çš„ç‹¬ç«‹è®¾ç½®
context["settings"] = copy.deepcopy(global_settings)
```

**é‡å¤è§¦å‘é˜²æŠ¤ï¼š**
```python
_duplicate_push_triggers = DefaultDictWithTimeout(ttl=300)
```

### 4. è¶…æ—¶æ§åˆ¶

```python
# AI API è¶…æ—¶
ai_timeout = 120  # 2 åˆ†é’Ÿ

# Git å…‹éš†è¶…æ—¶
CLONE_TIMEOUT_SEC = 20

# Webhook å¤„ç†è¶…æ—¶
push_trigger_pending_tasks_ttl = 300  # 5 åˆ†é’Ÿ
```

---

## å››ã€å¯è§‚æµ‹æ€§

### 1. æ—¥å¿—ç³»ç»Ÿ

**Loguru é…ç½®ï¼š** `pr_agent/log/__init__.py`

```python
def setup_logger(level="INFO", fmt=LoggingFormat.CONSOLE):
    # JSON æ ¼å¼ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
    logger.add(
        sys.stdout,
        filter=inv_analytics_filter,
        level=level,
        format="{message}",
        serialize=True,  # JSON
    )

    # æ§åˆ¶å°æ ¼å¼ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    logger.add(
        sys.stdout,
        level=level,
        colorize=True,
        filter=inv_analytics_filter,
    )

    # Analytics æ—¥å¿—ï¼ˆæ–‡ä»¶ï¼‰
    if log_folder:
        logger.add(
            log_file,
            filter=analytics_filter,
            level=level,
            serialize=True,
        )
```

**ç»“æ„åŒ–æ—¥å¿—ï¼š**
```python
get_logger().info(
    "Reviewing PR",
    artifact={
        "pr_url": pr_url,
        "num_files": len(files),
        "model": model
    }
)
```

### 2. è¿½è¸ªé›†æˆ

**LiteLLM Callbacksï¼š**

```toml
[litellm]
enable_callbacks = false
success_callback = ["langfuse", "langsmith"]
failure_callback = []
service_callback = []
```

**å…ƒæ•°æ®ï¼š**
```python
metadata = {
    "trace_name": command,
    "tags": [git_provider, command, f'version:{get_version()}'],
    "trace_metadata": {
        "command": command,
        "pr_url": pr_url,
    }
}
```

### 3. GitHub Actions è¾“å‡º

```python
def github_action_output(data, key):
    """
    å†™å…¥ GitHub Actions è¾“å‡º
    """
    if os.getenv('GITHUB_OUTPUT'):
        with open(os.getenv('GITHUB_OUTPUT'), 'a') as f:
            f.write(f"{key}={json.dumps(data)}\n")
```

---

## äº”ã€æ‰©å±•æ€§è®¾è®¡

### 1. æ·»åŠ æ–°çš„ Git Provider

**æ­¥éª¤ï¼š**
1. ç»§æ‰¿ `GitProvider`
2. å®ç°æŠ½è±¡æ–¹æ³•
3. åœ¨å·¥å‚ä¸­æ³¨å†Œ

**ç¤ºä¾‹ï¼š**
```python
# pr_agent/git_providers/my_provider.py
class MyProvider(GitProvider):
    def __init__(self, pr_url: str, token: str = None):
        # åˆå§‹åŒ– API å®¢æˆ·ç«¯
        pass

    def get_files(self) -> list:
        # è·å– PR æ–‡ä»¶åˆ—è¡¨
        pass

    def get_diff_files(self) -> list[FilePatchInfo]:
        # è·å– diff ä¿¡æ¯
        pass

    def publish_comment(self, comment: str):
        # å‘å¸ƒè¯„è®º
        pass

    # ... å…¶ä»–æŠ½è±¡æ–¹æ³•
```

### 2. æ·»åŠ æ–°çš„ Tool

**æ­¥éª¤ï¼š**
1. åˆ›å»º tool ç±»
2. å®ç° `__init__` å’Œ `async run()`
3. æ·»åŠ åˆ° `command2class`

**ç¤ºä¾‹ï¼š**
```python
# pr_agent/tools/pr_my_tool.py
class PRMyTool:
    def __init__(self, pr_url: str, args: list = None):
        self.git_provider = get_git_provider_with_context(pr_url)
        self.vars = {...}
        self.token_handler = TokenHandler(...)

    async def run(self):
        # 1. è·å– diff
        self.patches_diff = get_pr_diff(...)

        # 2. è°ƒç”¨ AI
        response = await self.ai_handler.chat_completion(...)

        # 3. å‘å¸ƒç»“æœ
        self.git_provider.publish_comment(response)

# pr_agent/agent/pr_agent.py
command2class = {
    "my_tool": PRMyTool,
    # ... å…¶ä»–å‘½ä»¤
}
```

### 3. æ·»åŠ æ–°çš„ Prompt æ¨¡æ¿

**æ­¥éª¤ï¼š**
1. åˆ›å»º `.toml` æ–‡ä»¶
2. å®šä¹‰ system å’Œ user prompts
3. ä½¿ç”¨ Jinja2 æ¨¡æ¿è¯­æ³•

**ç¤ºä¾‹ï¼š**
```toml
# pr_agent/settings/pr_my_tool_prompts.toml
[pr_my_tool_prompt]
system = """
You are an AI assistant that...
"""

user = """
Here is the PR information:
Title: {{ title }}
Description: {{ description }}
Diff:
{{ diff }}

Please analyze and provide...
"""
```

---

## å…­ã€å…³é”®æŠ€æœ¯æ ˆæ€»ç»“

### æ ¸å¿ƒæ¡†æ¶
- **Python 3.12+**: ä¸»è¦ç¼–ç¨‹è¯­è¨€
- **FastAPI/Uvicorn**: Web æ¡†æ¶å’Œ ASGI æœåŠ¡å™¨
- **asyncio**: å¼‚æ­¥ç¼–ç¨‹æ”¯æŒ

### AI é›†æˆ
- **LiteLLM**: ç»Ÿä¸€ AI æ¨¡å‹æ¥å£
- **tiktoken**: Token ç¼–ç å’Œè®¡æ•°
- **Jinja2**: Prompt æ¨¡æ¿å¼•æ“

### Git é›†æˆ
- **PyGithub**: GitHub API
- **python-gitlab**: GitLab API
- **atlassian-python-api**: Bitbucket API
- **GitPython**: Git æ“ä½œ

### é…ç½®ç®¡ç†
- **Dynaconf**: å¤šå±‚é…ç½®ç³»ç»Ÿ
- **pydantic**: æ•°æ®éªŒè¯

### æ—¥å¿—å’Œè¿½è¸ª
- **Loguru**: ç»“æ„åŒ–æ—¥å¿—
- **Langfuse/Langsmith**: å¯é€‰è¿½è¸ªé›†æˆ

### æµ‹è¯•
- **pytest**: å•å…ƒæµ‹è¯•
- **pytest-cov**: ä»£ç è¦†ç›–ç‡

### éƒ¨ç½²
- **Docker**: å®¹å™¨åŒ–éƒ¨ç½²
- **GitHub Actions**: CI/CD
- **Gunicorn**: ç”Ÿäº§æœåŠ¡å™¨ï¼ˆuvicorn workersï¼‰
